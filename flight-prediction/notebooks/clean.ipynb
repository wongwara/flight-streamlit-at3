{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Directory where the ZIP files are located (assuming it's relative)\n",
    "base_directory = '../data/raw/itineraries_csv'  \n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Define a regular expression pattern to match filenames ending with two lowercase letters\n",
    "file_pattern = re.compile(r'.*[a-z][a-z]\\.zip')\n",
    "\n",
    "# List all airport folders in the base directory\n",
    "airport_names = [name for name in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, name))]\n",
    "\n",
    "dfs = []  # Create a list to store DataFrames\n",
    "\n",
    "for airport_name in airport_names:\n",
    "    # Directory path for the current airport\n",
    "    zip_directory = os.path.join(base_directory, airport_name)\n",
    "    \n",
    "    # List all files in the airport's folder\n",
    "    file_list = os.listdir(zip_directory)\n",
    "\n",
    "    for filename in file_list:\n",
    "        if file_pattern.match(filename):\n",
    "            zip_file_path = os.path.join(zip_directory, filename)\n",
    "            csv_file_path_inside_zip = filename.replace('.zip', '.csv')\n",
    "            \n",
    "            # Create a ZipFile object and read the CSV file\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
    "                df = pd.read_csv(zf.open(csv_file_path_inside_zip))\n",
    "\n",
    "            # Append the DataFrame for this filename to the list of DataFrames\n",
    "            dfs.append(df)\n",
    "\n",
    "# Use pandas.concat to concatenate the list of DataFrames into a single DataFrame\n",
    "all_airport = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# legId                                      0\n",
    "# searchDate                                0\n",
    "# flightDate                                0\n",
    "# startingAirport                           0\n",
    "# destinationAirport                        0\n",
    "# travelDuration                            0\n",
    "# isBasicEconomy                            0\n",
    "# isRefundable                              0\n",
    "# totalFare                                 0 (y)\n",
    "# totalTravelDistance                  959619\n",
    "# segmentsDepartureTimeEpochSeconds         0\n",
    "# segmentsArrivalTimeEpochSeconds           0\n",
    "# segmentsArrivalAirportCode                0\n",
    "# segmentsDepartureAirportCode              0\n",
    "# segmentsAirlineCode                       0\n",
    "# segmentsEquipmentDescription         262676\n",
    "# segmentsDurationInSeconds                 0 -> sum\n",
    "# segmentsDistance                          0 -> sum\n",
    "# segmentsCabinCode                         0\n",
    "# -------\n",
    "# travelLayover (travelDuration - segmentsDurationInSeconds)\n",
    "# datediff (flightDate - searchDate)\n",
    "# transitAirportCode (list) -> check arrival departure \n",
    "# numberOfTransit -> count (transitAirportCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `travelLayover` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `travelDuration` into second**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a duration string to seconds\n",
    "def convert_duration_to_seconds(duration):\n",
    "    match = re.match(r'PT(\\d+)H(\\d+)M', duration)\n",
    "    \n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        total_seconds = hours * 3600 + minutes * 60\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'travelDuration' column and create a new column 'travelDurationInSeconds'\n",
    "all_airport['travelDurationInSeconds'] = all_airport['travelDuration'].apply(convert_duration_to_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28320.0\n",
       "1    22500.0\n",
       "2    32760.0\n",
       "3    22620.0\n",
       "4    51120.0\n",
       "Name: travelDurationInSeconds, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_airport['travelDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `durationinsecond`**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split and sum the values\n",
    "def split_and_sum(segment_duration):\n",
    "    segments = segment_duration.split('||')\n",
    "    return sum(map(int, segments))\n",
    "\n",
    "# Apply the function to the 'segmentsDurationInSeconds' column and create a new column 'totalDurationInSeconds'\n",
    "all_airport['totalDurationInSeconds'] = all_airport['segmentsDurationInSeconds'].apply(split_and_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19800\n",
       "1    20520\n",
       "2    20520\n",
       "3    19560\n",
       "4    25080\n",
       "Name: totalDurationInSeconds, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_airport['totalDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate `travelLayover`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8520.0\n",
       "1     1980.0\n",
       "2    12240.0\n",
       "3     3060.0\n",
       "4    26040.0\n",
       "Name: travelLayover, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_airport['travelLayover'] = all_airport['travelDurationInSeconds'] - all_airport['totalDurationInSeconds']\n",
    "all_airport['travelLayover'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "all_airport['SumsegmentsDurationInSeconds'] = all_airport['segmentsDurationInSeconds'].str.split(r'\\|\\|').apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "all_airport['SumsegmentsDurationInSeconds'] = all_airport['SumsegmentsDurationInSeconds'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepearte col by ||\n",
    "all_airport['segmentsArrivalAirportCode'] = all_airport['segmentsArrivalAirportCode'].str.split(r'\\|\\|')\n",
    "all_airport['segmentsDepartureAirportCode'] = all_airport['segmentsDepartureAirportCode'].str.split(r'\\|\\|')\n",
    "#find departure and arrival\n",
    "all_airport['Departure'] = all_airport['segmentsDepartureAirportCode'].apply(lambda x: x[0])\n",
    "all_airport['Arrival'] = all_airport['segmentsArrivalAirportCode'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new col to collect only transit airport\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming all_airport is your DataFrame\n",
    "\n",
    "def process_code_list(code_list):\n",
    "    if len(code_list) != 1:\n",
    "        code_list = code_list[1:] \n",
    "    return code_list\n",
    "\n",
    "all_airport['transitAirportCode'] = all_airport['segmentsDepartureAirportCode'].apply(process_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            943||1207\n",
       "1           None||None\n",
       "2           None||None\n",
       "3           None||None\n",
       "4            672||2178\n",
       "               ...    \n",
       "13519994     596||2135\n",
       "13519995    1104||2566\n",
       "13519996    1104||2566\n",
       "13519997    1104||2566\n",
       "13519998    1104||2566\n",
       "Name: segmentsDistance, Length: 13519999, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_airport['segmentsDistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "all_airport['SumsegmentsDistance'] = all_airport['segmentsDistance'].str.split(r'\\|\\|').apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "all_airport['SumsegmentsDistance'] = all_airport['SumsegmentsDistance'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new col to collect all airport\n",
    "all_airport['AllAirport'] = all_airport['transitAirportCode']\n",
    "all_airport['AllAirport'] = all_airport.apply(lambda row: [row['Departure']] + row['AllAirport'], axis=1)\n",
    "all_airport['AllAirport'] = all_airport.apply(lambda row: row['AllAirport'] + [row['Arrival']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airport2 = all_airport.drop(columns=['Departure', 'Arrival', 'segmentsDistance', 'segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw', 'segmentsDurationInSeconds', 'segmentsDistance', 'travelDuration', 'SumsegmentsDurationInSeconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airport2.rename(columns={'totalDurationInSeconds':'segment_totalDurationInSeconds', 'SumsegmentsDistance':'segment_totalDistance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airport2.to_feather('../data/all_airport_cleaned.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding -> label encoder, standard encoder -> save -> corr -> save result diff notebook -> split clean notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split ratio 80:20 -> train val test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2faf7d233e2b105e8d1a284702cec228a4712bc10b8e33a5c6f4a53cf932b354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Directory where the ZIP files are located (assuming it's relative)\n",
    "base_directory = '../data/raw/itineraries_csv'  \n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Define a regular expression pattern to match filenames ending with two lowercase letters\n",
    "file_pattern = re.compile(r'.*[a-z][a-z]\\.zip')\n",
    "\n",
    "# List all airport folders in the base directory\n",
    "airport_names = [name for name in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, name))]\n",
    "\n",
    "dfs = []  # Create a list to store DataFrames\n",
    "\n",
    "for airport_name in airport_names:\n",
    "    # Directory path for the current airport\n",
    "    zip_directory = os.path.join(base_directory, airport_name)\n",
    "    \n",
    "    # List all files in the airport's folder\n",
    "    file_list = os.listdir(zip_directory)\n",
    "\n",
    "    for filename in file_list:\n",
    "        if file_pattern.match(filename):\n",
    "            zip_file_path = os.path.join(zip_directory, filename)\n",
    "            csv_file_path_inside_zip = filename.replace('.zip', '.feather')\n",
    "            \n",
    "            # Create a ZipFile object and read the CSV file\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
    "                df = pd.read_feather(zf.open(csv_file_path_inside_zip))\n",
    "\n",
    "            # Append the DataFrame for this filename to the list of DataFrames\n",
    "            dfs.append(df)\n",
    "\n",
    "# Use pandas.concat to concatenate the list of DataFrames into a single DataFrame\n",
    "# df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# legId                                      0\n",
    "# searchDate                                0\n",
    "# flightDate                                0\n",
    "# startingAirport                           0\n",
    "# destinationAirport                        0\n",
    "# travelDuration                            0\n",
    "# isBasicEconomy                            0\n",
    "# isRefundable                              0\n",
    "# totalFare                                 0 (y)\n",
    "# totalTravelDistance                  959619\n",
    "# segmentsDepartureTimeEpochSeconds         0\n",
    "# segmentsArrivalTimeEpochSeconds           0\n",
    "# segmentsArrivalAirportCode                0\n",
    "# segmentsDepartureAirportCode              0\n",
    "# segmentsAirlineCode                       0\n",
    "# segmentsEquipmentDescription         262676\n",
    "# segmentsDurationInSeconds                 0 -> sum\n",
    "# segmentsDistance                          0 -> sum\n",
    "# segmentsCabinCode                         0\n",
    "# -------\n",
    "# travelLayover (travelDuration - segmentsDurationInSeconds)\n",
    "# datediff (flightDate - searchDate)\n",
    "# transitAirportCode (list) -> check arrival departure \n",
    "# numberOfTransit -> count (transitAirportCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `travelLayover` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `travelDuration` into second**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a duration string to seconds\n",
    "def convert_duration_to_seconds(duration):\n",
    "    match = re.match(r'PT(\\d+)H(\\d+)M', duration)\n",
    "    \n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        total_seconds = hours * 3600 + minutes * 60\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'travelDuration' column and create a new column 'travelDurationInSeconds'\n",
    "df['travelDurationInSeconds'] = df['travelDuration'].apply(convert_duration_to_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28320.0\n",
       "1    22500.0\n",
       "2    32760.0\n",
       "3    22620.0\n",
       "4    51120.0\n",
       "Name: travelDurationInSeconds, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['travelDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `durationinsecond`**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split and sum the values\n",
    "def split_and_sum(segment_duration):\n",
    "    segments = segment_duration.split('||')\n",
    "    return sum(map(int, segments))\n",
    "\n",
    "# Apply the function to the 'segmentsDurationInSeconds' column and create a new column 'totalDurationInSeconds'\n",
    "df['totalDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(split_and_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19800\n",
       "1    20520\n",
       "2    20520\n",
       "3    19560\n",
       "4    25080\n",
       "Name: totalDurationInSeconds, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['totalDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate `travelLayover`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8520.0\n",
       "1     1980.0\n",
       "2    12240.0\n",
       "3     3060.0\n",
       "4    26040.0\n",
       "Name: travelLayover, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['travelLayover'] = df['travelDurationInSeconds'] - df['totalDurationInSeconds']\n",
    "df['travelLayover'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cols = ['segmentsDepartureTimeEpochSeconds',\n",
    " 'segmentsArrivalTimeEpochSeconds',\n",
    " 'segmentsArrivalAirportCode',\n",
    " 'segmentsDepartureAirportCode',\n",
    " 'segmentsAirlineName',\n",
    " 'segmentsAirlineCode',\n",
    " 'segmentsEquipmentDescription',\n",
    " 'segmentsDurationInSeconds',\n",
    " 'segmentsDistance',\n",
    " 'segmentsCabinCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsDepartureTimeEpochSeconds'] = df['segmentsDepartureTimeEpochSeconds'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsArrivalTimeEpochSeconds'] = df['segmentsArrivalTimeEpochSeconds'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsArrivalAirportCode'] = df['segmentsArrivalAirportCode'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsDepartureAirportCode'] = df['segmentsDepartureAirportCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsAirlineName'] = df['segmentsAirlineName'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsAirlineCode'] = df['segmentsAirlineCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           <class 'str'>\n",
      "1           <class 'str'>\n",
      "2           <class 'str'>\n",
      "3           <class 'str'>\n",
      "4           <class 'str'>\n",
      "                ...      \n",
      "13519994    <class 'str'>\n",
      "13519995    <class 'str'>\n",
      "13519996    <class 'str'>\n",
      "13519997    <class 'str'>\n",
      "13519998    <class 'str'>\n",
      "Name: segmentsEquipmentDescription, Length: 13519999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['segmentsEquipmentDescription'].apply(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split the string and create a list\n",
    "def split_duration(segment):\n",
    "    return [int(value) for value in re.split(r'\\|\\|', segment)]\n",
    "\n",
    "# Apply the function to the 'segmentsDurationInSeconds' column\n",
    "df['segmentsDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(split_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_description(segment):\n",
    "    if segment and isinstance(segment, str):\n",
    "        return [description.strip() for description in re.split(r'\\|\\|', segment) if description]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the function to the 'segmentsEquipmentDescription' column\n",
    "df['segmentsEquipmentDescription'] = df['segmentsEquipmentDescription'].apply(split_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsDistance'] = df['segmentsDistance'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsCabinCode'] = df['segmentsCabinCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "df['SumsegmentsDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "df['SumsegmentsDurationInSeconds'] = df['SumsegmentsDurationInSeconds'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_element(x):\n",
    "    return x[0] if len(x) > 0 else None\n",
    "\n",
    "def get_last_element(x):\n",
    "    return x[-1] if len(x) > 0 else None\n",
    "\n",
    "df['Departure'] = df['segmentsDepartureAirportCode'].map(get_first_element)\n",
    "df['Arrival'] = df['segmentsArrivalAirportCode'].map(get_last_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Departure'] = df['segmentsDepartureAirportCode'].apply(lambda x: [x[0]])\n",
    "df['Arrival'] = df['segmentsArrivalAirportCode'].apply(lambda x: [x[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new col to collect only transit airport\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "def process_code_list(code_list):\n",
    "    if len(code_list) != 1:\n",
    "        code_list = code_list[1:] \n",
    "    return code_list\n",
    "\n",
    "df['transitAirportCode'] = df['segmentsDepartureAirportCode'].apply(process_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "df['SumsegmentsDistance'] = df['segmentsDistance'].apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "df['SumsegmentsDistance'] = df['SumsegmentsDistance'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AllAirport'] = df['transitAirportCode'] + df['Departure'] + df['Arrival']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreset_index().to_feather('../data/df.feather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_feather('../../data/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=['Departure', 'Arrival', 'segmentsDistance', 'segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw', 'segmentsDurationInSeconds', 'segmentsDistance', 'travelDuration', 'SumsegmentsDurationInSeconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.rename(columns={'totalDurationInSeconds':'segment_totalDurationInSeconds', 'SumsegmentsDistance':'segment_totalDistance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding -> label encoder, standard encoder -> save -> corr -> save result diff notebook -> split clean notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform date column: searchDate\n",
    "df_cleaned['searchDate'] = pd.to_datetime(df_cleaned['searchDate'])\n",
    "df_cleaned['searchDate_day'] = df_cleaned['searchDate'].dt.day\n",
    "df_cleaned['searchDate_month'] = df_cleaned['searchDate'].dt.month\n",
    "df_cleaned['searchDate_year'] = df_cleaned['searchDate'].dt.year\n",
    "\n",
    "#transform date column: flightDate\n",
    "df_cleaned['flightDate'] = pd.to_datetime(df_cleaned['flightDate'])\n",
    "df_cleaned['flightDate_day'] = df_cleaned['flightDate'].dt.day\n",
    "df_cleaned['flightDate_month'] = df_cleaned['flightDate'].dt.month\n",
    "df_cleaned['flightDate_year'] = df_cleaned['flightDate'].dt.year\n",
    "\n",
    "#drop date cols\n",
    "df_cleaned = df_cleaned.drop(columns=['searchDate', 'flightDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsArrivalAirportCode'] = df_cleaned['segmentsArrivalAirportCode'].apply(lambda x: pd.factorize(x)[0])\n",
    "df_cleaned['segmentsDepartureAirportCode'] = df_cleaned['segmentsDepartureAirportCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsAirlineName'] = df_cleaned['segmentsAirlineName'].apply(lambda x: pd.factorize(x)[0])\n",
    "df_cleaned['segmentsAirlineCode'] = df_cleaned['segmentsAirlineCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsEquipmentDescription'] = df_cleaned['segmentsEquipmentDescription'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsCabinCode'] = df_cleaned['segmentsCabinCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['AllAirport'] = df_cleaned['AllAirport'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['transitAirportCode'] = df_cleaned['transitAirportCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [1653098280, 1653115980]\n",
       "1           [1653062160, 1653069060]\n",
       "2           [1653051900, 1653069060]\n",
       "3           [1653105360, 1653114000]\n",
       "4           [1653108060, 1653141600]\n",
       "                      ...           \n",
       "13519994    [1655294700, 1655327100]\n",
       "13519995    [1655321160, 1655338500]\n",
       "13519996    [1655306100, 1655326500]\n",
       "13519997    [1655292000, 1655312400]\n",
       "13519998    [1655292000, 1655326500]\n",
       "Name: segmentsDepartureTimeEpochSeconds, Length: 13519999, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['segmentsDepartureTimeEpochSeconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['DepartTime'] = df_cleaned['segmentsDepartureTimeEpochSeconds'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['DepartTime'] = pd.to_datetime(df_cleaned['DepartTime'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract and create new columns for hours, minutes, and seconds\n",
    "df_cleaned['DepartTime_hour'] = df_cleaned['DepartTime'].dt.hour\n",
    "df_cleaned['DepartTime_minute'] = df_cleaned['DepartTime'].dt.minute\n",
    "df_cleaned['DepartTime_second'] = df_cleaned['DepartTime'].dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=['DepartTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[['totalTravelDistance', 'isNonStop', 'isBasicEconomy', 'startingAirport', 'destinationAirport', 'segmentsCabinCode','flightDate_day', 'flightDate_month', 'flightDate_year',\n",
    "                         'DepartTime_hour', 'DepartTime_minute', 'DepartTime_second','totalFare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defined num_cols and cat_cols\n",
    "import numpy as np\n",
    "cols = df_cleaned.columns.to_list()\n",
    "num_cols = df_cleaned.select_dtypes(np.number).columns.to_list()\n",
    "segment_cols = ['segmentsDepartureTimeEpochSeconds', 'segmentsArrivalTimeEpochSeconds', 'segmentsArrivalAirportCode', 'segmentsDepartureAirportCode', 'segmentsAirlineName', 'segmentsAirlineCode',\n",
    "                'segmentsEquipmentDescription', 'segmentsCabinCode', 'transitAirportCode', 'AllAirport']\n",
    "cat_cols = list(set(cols) - set(num_cols) - set(segment_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['totalTravelDistance']= df_cleaned['totalTravelDistance'].fillna(df_cleaned['totalTravelDistance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_cleaned[cat_cols] = df_cleaned[cat_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale numeric column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_cleaned[num_cols] = scaler.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanedreset_index().to_feather('../../data/processed/df_cleaned2_select_cols.feather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_feather(\"../../data/processed/df_cleaned2_select_cols.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/baiporthn/Projects/Adv_ml/flight-streamlit-at3/flight-prediction/notebooks/TP_notebooks', '/Users/baiporthn/opt/anaconda3/lib/python39.zip', '/Users/baiporthn/opt/anaconda3/lib/python3.9', '/Users/baiporthn/opt/anaconda3/lib/python3.9/lib-dynload', '', '/Users/baiporthn/.local/lib/python3.9/site-packages', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/aeosa', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/Users/baiporthn/.ipython', '../../src/', '../../src/', '../../src/', '../../src/', '../../src/', '../../src/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.make_dataset import *\n",
    "features, target = pop_target(df_cleaned, 'totalFare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(features, target, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sets(X_train=None, y_train=None, X_val=None, y_val=None, X_test=None, y_test=None, path='../data/processed/'):\n",
    "\n",
    "    import pandas as pd\n",
    "    import os.path\n",
    "\n",
    "    if X_train is not None:\n",
    "        X_train.reset_index().to_feather(f'{path}X_train.feather')\n",
    "    if X_val is not None:\n",
    "        X_val.reset_index().to_feather(f'{path}X_val.feather')\n",
    "    if X_test is not None:\n",
    "        X_test.reset_index().to_feather(f'{path}X_test.feather')\n",
    "    if y_train is not None:\n",
    "        y_train = y_train.to_frame()\n",
    "        y_train.reset_index().to_feather(f'{path}y_train.feather')\n",
    "    if y_val is not None:\n",
    "        y_val = y_val.to_frame()\n",
    "        y_val.reset_index().to_feather(f'{path}y_val.feather')\n",
    "    if y_test is not None:\n",
    "        y_test = y_test.to_frame()\n",
    "        y_test.reset_index().to_feather(f'{path}y_test.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sets(path='../data/processed/'):\n",
    "    \"\"\"Load the different locally save sets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the folder where the sets are saved (default: '../data/processed/')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        Features for the training set\n",
    "    Numpy Array\n",
    "        Target for the training set\n",
    "    Numpy Array\n",
    "        Features for the validation set\n",
    "    Numpy Array\n",
    "        Target for the validation set\n",
    "    Numpy Array\n",
    "        Features for the testing set\n",
    "    Numpy Array\n",
    "        Target for the testing set\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os.path\n",
    "\n",
    "    X_train = pd.read_feather(f'{path}X_train.feather') if os.path.isfile(f'{path}X_train.feather') else None\n",
    "    X_val   = pd.read_feather(f'{path}X_val.feather') if os.path.isfile(f'{path}X_val.feather')   else None\n",
    "    X_test  = pd.read_feather(f'{path}X_test.feather') if os.path.isfile(f'{path}X_test.feather')  else None\n",
    "    y_train = pd.read_feather(f'{path}y_train.feather') if os.path.isfile(f'{path}y_train.feather') else None\n",
    "    y_val   = pd.read_feather(f'{path}y_val.feather') if os.path.isfile(f'{path}y_val.feather')   else None\n",
    "    y_test  = pd.read_feather(f'{path}y_test.feather') if os.path.isfile(f'{path}y_test.feather')  else None\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split ratio 80:20 -> train val test\n",
    "# from data.make_dataset import *\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../../data/processed/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2faf7d233e2b105e8d1a284702cec228a4712bc10b8e33a5c6f4a53cf932b354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

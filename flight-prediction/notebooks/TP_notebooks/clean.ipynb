{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Directory where the ZIP files are located\n",
    "base_directory = '../../data/raw/itineraries_csv'\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Define a regular expression pattern to match filenames ending with two lowercase letters\n",
    "file_pattern = re.compile(r'.*[a-z][a-z]\\.zip')\n",
    "\n",
    "# List all airport folders in the base directory\n",
    "airport_names = [name for name in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, name))]\n",
    "\n",
    "dfs = []  # Create a list to store DataFrames\n",
    "\n",
    "for airport_name in airport_names:\n",
    "    # Directory path for the current airport\n",
    "    zip_directory = os.path.join(base_directory, airport_name)\n",
    "    \n",
    "    # List all files in the airport's folder\n",
    "    file_list = os.listdir(zip_directory)\n",
    "\n",
    "    for filename in file_list:\n",
    "        if file_pattern.match(filename):\n",
    "            zip_file_path = os.path.join(zip_directory, filename)\n",
    "            csv_file_path_inside_zip = filename.replace('.zip', '.csv')\n",
    "            \n",
    "            # Create a ZipFile object and read the CSV file\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zf:\n",
    "                df = pd.read_csv(zf.open(csv_file_path_inside_zip))\n",
    "\n",
    "            # Append the DataFrame for this filename to the list of DataFrames\n",
    "            dfs.append(df)\n",
    "\n",
    "# Use pandas.concat to concatenate the list of DataFrames into a single DataFrame\n",
    "all_airport = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# legId                                      0\n",
    "# searchDate                                0\n",
    "# flightDate                                0\n",
    "# startingAirport                           0\n",
    "# destinationAirport                        0\n",
    "# travelDuration                            0\n",
    "# isBasicEconomy                            0\n",
    "# isRefundable                              0\n",
    "# totalFare                                 0 (y)\n",
    "# totalTravelDistance                  959619\n",
    "# segmentsDepartureTimeEpochSeconds         0\n",
    "# segmentsArrivalTimeEpochSeconds           0\n",
    "# segmentsArrivalAirportCode                0\n",
    "# segmentsDepartureAirportCode              0\n",
    "# segmentsAirlineCode                       0\n",
    "# segmentsEquipmentDescription         262676\n",
    "# segmentsDurationInSeconds                 0 -> sum\n",
    "# segmentsDistance                          0 -> sum\n",
    "# segmentsCabinCode                         0\n",
    "# -------\n",
    "# travelLayover (travelDuration - segmentsDurationInSeconds)\n",
    "# datediff (flightDate - searchDate)\n",
    "# transitAirportCode (list) -> check arrival departure \n",
    "# numberOfTransit -> count (transitAirportCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `travelLayover` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `travelDuration` into second**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a duration string to seconds\n",
    "def convert_duration_to_seconds(duration):\n",
    "    match = re.match(r'PT(\\d+)H(\\d+)M', duration)\n",
    "    \n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        total_seconds = hours * 3600 + minutes * 60\n",
    "        return total_seconds\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'travelDuration' column and create a new column 'travelDurationInSeconds'\n",
    "df['travelDurationInSeconds'] = df['travelDuration'].apply(convert_duration_to_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28320.0\n",
       "1    22500.0\n",
       "2    32760.0\n",
       "3    22620.0\n",
       "4    51120.0\n",
       "Name: travelDurationInSeconds, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['travelDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `durationinsecond`**`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split and sum the values\n",
    "def split_and_sum(segment_duration):\n",
    "    segments = segment_duration.split('||')\n",
    "    return sum(map(int, segments))\n",
    "\n",
    "# Apply the function to the 'segmentsDurationInSeconds' column and create a new column 'totalDurationInSeconds'\n",
    "df['totalDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(split_and_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19800\n",
       "1    20520\n",
       "2    20520\n",
       "3    19560\n",
       "4    25080\n",
       "Name: totalDurationInSeconds, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['totalDurationInSeconds'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate `travelLayover`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8520.0\n",
       "1     1980.0\n",
       "2    12240.0\n",
       "3     3060.0\n",
       "4    26040.0\n",
       "Name: travelLayover, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['travelLayover'] = df['travelDurationInSeconds'] - df['totalDurationInSeconds']\n",
    "df['travelLayover'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cols = ['segmentsDepartureTimeEpochSeconds',\n",
    " 'segmentsArrivalTimeEpochSeconds',\n",
    " 'segmentsArrivalAirportCode',\n",
    " 'segmentsDepartureAirportCode',\n",
    " 'segmentsAirlineName',\n",
    " 'segmentsAirlineCode',\n",
    " 'segmentsEquipmentDescription',\n",
    " 'segmentsDurationInSeconds',\n",
    " 'segmentsDistance',\n",
    " 'segmentsCabinCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsDepartureTimeEpochSeconds'] = df['segmentsDepartureTimeEpochSeconds'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsArrivalTimeEpochSeconds'] = df['segmentsArrivalTimeEpochSeconds'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsArrivalAirportCode'] = df['segmentsArrivalAirportCode'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsDepartureAirportCode'] = df['segmentsDepartureAirportCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsAirlineName'] = df['segmentsAirlineName'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsAirlineCode'] = df['segmentsAirlineCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split the string and create a list\n",
    "def split_duration(segment):\n",
    "    return [int(value) for value in re.split(r'\\|\\|', segment)]\n",
    "\n",
    "# Apply the function to the 'segmentsDurationInSeconds' column\n",
    "df['segmentsDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(split_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_description(segment):\n",
    "    if segment and isinstance(segment, str):\n",
    "        return [description.strip() for description in re.split(r'\\|\\|', segment) if description]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the function to the 'segmentsEquipmentDescription' column\n",
    "df['segmentsEquipmentDescription'] = df['segmentsEquipmentDescription'].apply(split_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentsDistance'] = df['segmentsDistance'].apply(lambda x: re.split(r'\\|\\|', x))\n",
    "df['segmentsCabinCode'] = df['segmentsCabinCode'].apply(lambda x: re.split(r'\\|\\|', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "df['SumsegmentsDurationInSeconds'] = df['segmentsDurationInSeconds'].apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "df['SumsegmentsDurationInSeconds'] = df['SumsegmentsDurationInSeconds'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_element(x):\n",
    "    return x[0] if len(x) > 0 else None\n",
    "\n",
    "def get_last_element(x):\n",
    "    return x[-1] if len(x) > 0 else None\n",
    "\n",
    "df['Departure'] = df['segmentsDepartureAirportCode'].map(get_first_element)\n",
    "df['Arrival'] = df['segmentsArrivalAirportCode'].map(get_last_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Departure'] = df['segmentsDepartureAirportCode'].apply(lambda x: [x[0]])\n",
    "df['Arrival'] = df['segmentsArrivalAirportCode'].apply(lambda x: [x[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new col to collect only transit airport\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "def process_code_list(code_list):\n",
    "    if len(code_list) != 1:\n",
    "        code_list = code_list[1:] \n",
    "    return code_list\n",
    "\n",
    "df['transitAirportCode'] = df['segmentsDepartureAirportCode'].apply(process_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Sum of duration\n",
    "df['SumsegmentsDistance'] = df['segmentsDistance'].apply(lambda x: [pd.to_numeric(value, errors='coerce') for value in x])\n",
    "df['SumsegmentsDistance'] = df['SumsegmentsDistance'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AllAirport'] = df['transitAirportCode'] + df['Departure'] + df['Arrival']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_feather('../../data/df_notsplit.feather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_feather('../../data/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>legId</th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>travelDuration</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>isRefundable</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>...</th>\n",
       "      <th>segmentsDepartureAirportCode</th>\n",
       "      <th>segmentsAirlineName</th>\n",
       "      <th>segmentsAirlineCode</th>\n",
       "      <th>segmentsEquipmentDescription</th>\n",
       "      <th>segmentsDurationInSeconds</th>\n",
       "      <th>segmentsDistance</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "      <th>travelDurationInSeconds</th>\n",
       "      <th>totalDurationInSeconds</th>\n",
       "      <th>travelLayover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1b137527b9175d7d930c3af82e70ae0</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT7H52M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>103.98</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK||DEN</td>\n",
       "      <td>Frontier Airlines||Frontier Airlines</td>\n",
       "      <td>F9||F9</td>\n",
       "      <td>||Airbus A320</td>\n",
       "      <td>9180||10620</td>\n",
       "      <td>943||1207</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>28320.0</td>\n",
       "      <td>19800</td>\n",
       "      <td>8520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d813ebd107e3fa700206c0d96015da7a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H15M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>||AIRBUS INDUSTRIE A320 SHARKLETS</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>20520</td>\n",
       "      <td>1980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e8ece5ad6f5962c696e06e031fc2a24a</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT9H6M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>216.58</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK||LAX</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...</td>\n",
       "      <td>4920||15600</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>32760.0</td>\n",
       "      <td>20520</td>\n",
       "      <td>12240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c004a54681335100f326c9613b3c9448</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT6H17M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>237.58</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK||LAS</td>\n",
       "      <td>Spirit Airlines||Spirit Airlines</td>\n",
       "      <td>NK||NK</td>\n",
       "      <td>AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319</td>\n",
       "      <td>5580||13980</td>\n",
       "      <td>None||None</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>22620.0</td>\n",
       "      <td>19560</td>\n",
       "      <td>3060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a42bbf77211b4afa7b9e14005949120</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>PT14H12M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>307.21</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK||SEA</td>\n",
       "      <td>Alaska Airlines||Alaska Airlines</td>\n",
       "      <td>AS||AS</td>\n",
       "      <td>Boeing 737-900||Boeing 737-900</td>\n",
       "      <td>7500||17580</td>\n",
       "      <td>672||2178</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>51120.0</td>\n",
       "      <td>25080</td>\n",
       "      <td>26040.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              legId  searchDate  flightDate startingAirport  \\\n",
       "0  e1b137527b9175d7d930c3af82e70ae0  2022-04-19  2022-05-20             OAK   \n",
       "1  d813ebd107e3fa700206c0d96015da7a  2022-04-19  2022-05-20             OAK   \n",
       "2  e8ece5ad6f5962c696e06e031fc2a24a  2022-04-19  2022-05-20             OAK   \n",
       "3  c004a54681335100f326c9613b3c9448  2022-04-19  2022-05-20             OAK   \n",
       "4  4a42bbf77211b4afa7b9e14005949120  2022-04-19  2022-05-20             OAK   \n",
       "\n",
       "  destinationAirport travelDuration  isBasicEconomy  isRefundable  isNonStop  \\\n",
       "0                ATL        PT7H52M           False         False      False   \n",
       "1                ATL        PT6H15M           False         False      False   \n",
       "2                ATL         PT9H6M           False         False      False   \n",
       "3                ATL        PT6H17M           False         False      False   \n",
       "4                ATL       PT14H12M           False         False      False   \n",
       "\n",
       "   totalFare  ...  segmentsDepartureAirportCode  \\\n",
       "0     103.98  ...                      OAK||DEN   \n",
       "1     216.58  ...                      OAK||LAX   \n",
       "2     216.58  ...                      OAK||LAX   \n",
       "3     237.58  ...                      OAK||LAS   \n",
       "4     307.21  ...                      OAK||SEA   \n",
       "\n",
       "                    segmentsAirlineName segmentsAirlineCode  \\\n",
       "0  Frontier Airlines||Frontier Airlines              F9||F9   \n",
       "1      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "2      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "3      Spirit Airlines||Spirit Airlines              NK||NK   \n",
       "4      Alaska Airlines||Alaska Airlines              AS||AS   \n",
       "\n",
       "                        segmentsEquipmentDescription  \\\n",
       "0                                      ||Airbus A320   \n",
       "1                  ||AIRBUS INDUSTRIE A320 SHARKLETS   \n",
       "2  AIRBUS INDUSTRIE A320 SHARKLETS||AIRBUS INDUST...   \n",
       "3       AIRBUS INDUSTRIE A320 SHARKLETS||Airbus A319   \n",
       "4                     Boeing 737-900||Boeing 737-900   \n",
       "\n",
       "  segmentsDurationInSeconds segmentsDistance segmentsCabinCode  \\\n",
       "0               9180||10620        943||1207      coach||coach   \n",
       "1               4920||15600       None||None      coach||coach   \n",
       "2               4920||15600       None||None      coach||coach   \n",
       "3               5580||13980       None||None      coach||coach   \n",
       "4               7500||17580        672||2178      coach||coach   \n",
       "\n",
       "  travelDurationInSeconds totalDurationInSeconds travelLayover  \n",
       "0                 28320.0                  19800        8520.0  \n",
       "1                 22500.0                  20520        1980.0  \n",
       "2                 32760.0                  20520       12240.0  \n",
       "3                 22620.0                  19560        3060.0  \n",
       "4                 51120.0                  25080       26040.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=['Departure', 'Arrival', 'segmentsDistance', 'segmentsDepartureTimeRaw', 'segmentsArrivalTimeRaw', 'segmentsDurationInSeconds', 'segmentsDistance', 'travelDuration', 'SumsegmentsDurationInSeconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.rename(columns={'totalDurationInSeconds':'segment_totalDurationInSeconds', 'SumsegmentsDistance':'segment_totalDistance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding -> label encoder, standard encoder -> save -> corr -> save result diff notebook -> split clean notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform date column: searchDate\n",
    "df_cleaned['searchDate'] = pd.to_datetime(df_cleaned['searchDate'])\n",
    "df_cleaned['searchDate_day'] = df_cleaned['searchDate'].dt.day\n",
    "df_cleaned['searchDate_month'] = df_cleaned['searchDate'].dt.month\n",
    "df_cleaned['searchDate_year'] = df_cleaned['searchDate'].dt.year\n",
    "\n",
    "#transform date column: flightDate\n",
    "df_cleaned['flightDate'] = pd.to_datetime(df_cleaned['flightDate'])\n",
    "df_cleaned['flightDate_day'] = df_cleaned['flightDate'].dt.day\n",
    "df_cleaned['flightDate_month'] = df_cleaned['flightDate'].dt.month\n",
    "df_cleaned['flightDate_year'] = df_cleaned['flightDate'].dt.year\n",
    "\n",
    "#drop date cols\n",
    "df_cleaned = df_cleaned.drop(columns=['searchDate', 'flightDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsArrivalAirportCode'] = df_cleaned['segmentsArrivalAirportCode'].apply(lambda x: pd.factorize(x)[0])\n",
    "df_cleaned['segmentsDepartureAirportCode'] = df_cleaned['segmentsDepartureAirportCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsAirlineName'] = df_cleaned['segmentsAirlineName'].apply(lambda x: pd.factorize(x)[0])\n",
    "df_cleaned['segmentsAirlineCode'] = df_cleaned['segmentsAirlineCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsEquipmentDescription'] = df_cleaned['segmentsEquipmentDescription'].apply(lambda x: pd.factorize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['segmentsCabinCode'] = df_cleaned['segmentsCabinCode'].apply(lambda x: pd.factorize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['AllAirport'] = df_cleaned['AllAirport'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['transitAirportCode'] = df_cleaned['transitAirportCode'].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [1653098280, 1653115980]\n",
       "1           [1653062160, 1653069060]\n",
       "2           [1653051900, 1653069060]\n",
       "3           [1653105360, 1653114000]\n",
       "4           [1653108060, 1653141600]\n",
       "                      ...           \n",
       "13519994    [1655294700, 1655327100]\n",
       "13519995    [1655321160, 1655338500]\n",
       "13519996    [1655306100, 1655326500]\n",
       "13519997    [1655292000, 1655312400]\n",
       "13519998    [1655292000, 1655326500]\n",
       "Name: segmentsDepartureTimeEpochSeconds, Length: 13519999, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['segmentsDepartureTimeEpochSeconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['DepartTime'] = df_cleaned['segmentsDepartureTimeEpochSeconds'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['DepartTime'] = pd.to_datetime(df_cleaned['DepartTime'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract and create new columns for hours, minutes, and seconds\n",
    "df_cleaned['DepartTime_hour'] = df_cleaned['DepartTime'].dt.hour\n",
    "df_cleaned['DepartTime_minute'] = df_cleaned['DepartTime'].dt.minute\n",
    "df_cleaned['DepartTime_second'] = df_cleaned['DepartTime'].dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=['DepartTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[['totalTravelDistance', 'isNonStop', 'isBasicEconomy', 'startingAirport', 'destinationAirport', 'segmentsCabinCode','flightDate_day', 'flightDate_month', 'flightDate_year',\n",
    "                         'DepartTime_hour', 'DepartTime_minute', 'DepartTime_second','totalFare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>isBasicEconomy</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>segmentsCabinCode</th>\n",
       "      <th>flightDate_day</th>\n",
       "      <th>flightDate_month</th>\n",
       "      <th>flightDate_year</th>\n",
       "      <th>DepartTime_hour</th>\n",
       "      <th>DepartTime_minute</th>\n",
       "      <th>DepartTime_second</th>\n",
       "      <th>totalFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>216.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>216.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>237.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2850.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>OAK</td>\n",
       "      <td>ATL</td>\n",
       "      <td>coach||coach</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>307.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalTravelDistance  isNonStop  isBasicEconomy startingAirport  \\\n",
       "0               2150.0      False           False             OAK   \n",
       "1                  NaN      False           False             OAK   \n",
       "2                  NaN      False           False             OAK   \n",
       "3                  NaN      False           False             OAK   \n",
       "4               2850.0      False           False             OAK   \n",
       "\n",
       "  destinationAirport segmentsCabinCode  flightDate_day  flightDate_month  \\\n",
       "0                ATL      coach||coach              20                 5   \n",
       "1                ATL      coach||coach              20                 5   \n",
       "2                ATL      coach||coach              20                 5   \n",
       "3                ATL      coach||coach              20                 5   \n",
       "4                ATL      coach||coach              20                 5   \n",
       "\n",
       "   flightDate_year  DepartTime_hour  DepartTime_minute  DepartTime_second  \\\n",
       "0             2022                0                  0                  1   \n",
       "1             2022                0                  0                  1   \n",
       "2             2022                0                  0                  1   \n",
       "3             2022                0                  0                  1   \n",
       "4             2022                0                  0                  1   \n",
       "\n",
       "   totalFare  \n",
       "0     103.98  \n",
       "1     216.58  \n",
       "2     216.58  \n",
       "3     237.58  \n",
       "4     307.21  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defined num_cols and cat_cols\n",
    "import numpy as np\n",
    "cols = df_cleaned.columns.to_list()\n",
    "num_cols = df_cleaned.select_dtypes(np.number).columns.to_list()\n",
    "# segment_cols = ['segmentsDepartureTimeEpochSeconds', 'segmentsArrivalTimeEpochSeconds', 'segmentsArrivalAirportCode', 'segmentsDepartureAirportCode', 'segmentsAirlineName', 'segmentsAirlineCode',\n",
    "#                 'segmentsEquipmentDescription', 'segmentsCabinCode', 'transitAirportCode', 'AllAirport']\n",
    "cat_cols = list(set(cols) - set(num_cols) - set(segment_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.append('segmentsCabinCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['totalTravelDistance']= df_cleaned['totalTravelDistance'].fillna(df_cleaned['totalTravelDistance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_cleaned[cat_cols] = df_cleaned[cat_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale numeric column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_cleaned[num_cols] = scaler.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.reset_index().to_feather('../../data/processed/df_cleaned_select_cols.feather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_feather('../../data/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['legId',\n",
       " 'searchDate',\n",
       " 'flightDate',\n",
       " 'startingAirport',\n",
       " 'destinationAirport',\n",
       " 'travelDuration',\n",
       " 'isBasicEconomy',\n",
       " 'isRefundable',\n",
       " 'isNonStop',\n",
       " 'totalFare',\n",
       " 'totalTravelDistance',\n",
       " 'segmentsDepartureTimeEpochSeconds',\n",
       " 'segmentsDepartureTimeRaw',\n",
       " 'segmentsArrivalTimeEpochSeconds',\n",
       " 'segmentsArrivalTimeRaw',\n",
       " 'segmentsArrivalAirportCode',\n",
       " 'segmentsDepartureAirportCode',\n",
       " 'segmentsAirlineName',\n",
       " 'segmentsAirlineCode',\n",
       " 'segmentsEquipmentDescription',\n",
       " 'segmentsDurationInSeconds',\n",
       " 'segmentsDistance',\n",
       " 'segmentsCabinCode',\n",
       " 'travelDurationInSeconds',\n",
       " 'totalDurationInSeconds',\n",
       " 'travelLayover',\n",
       " 'SumsegmentsDurationInSeconds',\n",
       " 'Departure',\n",
       " 'Arrival',\n",
       " 'transitAirportCode',\n",
       " 'SumsegmentsDistance',\n",
       " 'AllAirport']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df_cleaned.columns.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols:\n",
    "    print(i, df_cleaned[i].columns.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/baiporthn/Projects/Adv_ml/flight-streamlit-at3/flight-prediction/notebooks/TP_notebooks', '/Users/baiporthn/opt/anaconda3/lib/python39.zip', '/Users/baiporthn/opt/anaconda3/lib/python3.9', '/Users/baiporthn/opt/anaconda3/lib/python3.9/lib-dynload', '', '/Users/baiporthn/.local/lib/python3.9/site-packages', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/aeosa', '/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/Users/baiporthn/.ipython', '../../src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baiporthn/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from data.make_dataset import *\n",
    "features, target = pop_target(df_cleaned, 'totalFare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(features, target, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.make_dataset import *\n",
    "\n",
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split ratio 80:20 -> train val test\n",
    "# from data.make_dataset import *\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@misc{omalley2019kerastuner,\n",
    "    title        = {KerasTuner},\n",
    "    author       = {O'Malley, Tom and Bursztein, Elie and Long, James and Chollet, Fran\\c{c}ois and Jin, Haifeng and Invernizzi, Luca and others},\n",
    "    year         = 2019,\n",
    "    howpublished = {\\url{https://github.com/keras-team/keras-tuner}}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2faf7d233e2b105e8d1a284702cec228a4712bc10b8e33a5c6f4a53cf932b354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
